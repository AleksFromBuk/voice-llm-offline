import json
import logging
import os
import queue
import threading
import re
from typing import Optional, Tuple
import numpy as np
import sounddevice as sd
import tkinter as tk
from tkinter import scrolledtext, messagebox, ttk, Checkbutton, BooleanVar
from vosk import Model, KaldiRecognizer
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import torch


class ProfessionalVoiceTranscriber:
    """
    –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –≥–æ–ª–æ—Å–æ–≤–æ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–æ—Ä —Å —Ä–µ–∞–ª—å–Ω–æ –ø–æ–ª–µ–∑–Ω–æ–π LLM –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π
    """

    def __init__(self, root: tk.Tk) -> None:
        self.root = root
        self.root.title("üé§ –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–æ—Ä")
        self.root.geometry("950x750")

        # –û—á–µ—Ä–µ–¥–∏ –¥–ª—è –º–µ–∂–ø–æ—Ç–æ—á–Ω–æ–≥–æ –æ–±—â–µ–Ω–∏—è
        self.text_queue = queue.Queue()
        self.status_queue = queue.Queue()

        # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è
        self.stop_event = threading.Event()
        self.recording_lock = threading.Lock()
        self.models_loaded = False
        self.is_recording = False

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
        self.sample_rate = 16000
        self.chunk_size = 4000

        # LLM –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        self.use_llm = BooleanVar(value=True)  # –ì–∞–ª–æ—á–∫–∞ –≤–∫–ª—é—á–µ–Ω–∏—è LLM
        self.llm_processing = False

        # –ò—Å—Ç–æ—Ä–∏—è –¥–ª—è –∑–∞–º–µ–Ω—ã —Ç–µ–∫—Å—Ç–∞
        self.last_raw_text = ""

        self._init_ui()
        self.models_thread = threading.Thread(target=self._load_models, daemon=True)
        self.models_thread.start()
        self.root.after(100, self._process_queues)

    def _init_ui(self):
        """–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏"""
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        title_frame = tk.Frame(self.root, bg="#2c3e50")
        title_frame.pack(fill=tk.X, padx=10, pady=10)

        title_label = tk.Label(
            title_frame,
            text="üé§ –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ì–æ–ª–æ—Å–æ–≤–æ–π –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–æ—Ä",
            font=("Arial", 16, "bold"),
            fg="white", bg="#2c3e50"
        )
        title_label.pack(pady=10)

        # –ü–∞–Ω–µ–ª—å –Ω–∞—Å—Ç—Ä–æ–µ–∫
        settings_frame = tk.Frame(self.root)
        settings_frame.pack(fill=tk.X, padx=15, pady=5)

        # –ì–∞–ª–æ—á–∫–∞ –≤–∫–ª—é—á–µ–Ω–∏—è LLM
        self.llm_checkbox = Checkbutton(
            settings_frame,
            text="–í–∫–ª—é—á–∏—Ç—å —É–ª—É—á—à–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ (LLM)",
            variable=self.use_llm,
            font=("Arial", 10)
        )
        self.llm_checkbox.pack(side=tk.LEFT)

        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª—è—Ö
        model_info = tk.Label(
            settings_frame,
            text="Vosk (—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ) + RUT5-Normalizer (—É–ª—É—á—à–µ–Ω–∏–µ)",
            font=("Arial", 9),
            fg="#666"
        )
        model_info.pack(side=tk.RIGHT)

        # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –∑–∞–≥—Ä—É–∑–∫–∏
        self.progress_frame = tk.Frame(self.root)
        self.progress_frame.pack(fill=tk.X, padx=20, pady=10)

        self.progress_label = tk.Label(
            self.progress_frame,
            text="–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π...",
            font=("Arial", 10)
        )
        self.progress_label.pack()

        self.progress = ttk.Progressbar(self.progress_frame, mode="indeterminate")
        self.progress.pack(fill=tk.X, pady=5)
        self.progress.start()

        # –û—Å–Ω–æ–≤–Ω–æ–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –ø–æ–ª–µ
        text_frame = tk.Frame(self.root)
        text_frame.pack(padx=15, pady=10, fill=tk.BOTH, expand=True)

        self.text_widget = scrolledtext.ScrolledText(
            text_frame,
            wrap=tk.WORD,
            width=90,
            height=22,
            font=("Arial", 11),
            bg="#f8f9fa"
        )
        self.text_widget.pack(fill=tk.BOTH, expand=True)

        # –ü–∞–Ω–µ–ª—å —Å—Ç–∞—Ç—É—Å–∞ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        control_frame = tk.Frame(self.root)
        control_frame.pack(fill=tk.X, padx=15, pady=15)

        self.status_var = tk.StringVar(value="‚è≥ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π...")
        status_label = tk.Label(
            control_frame,
            textvariable=self.status_var,
            font=("Arial", 10),
            fg="#666666"
        )
        status_label.pack(side=tk.LEFT, anchor=tk.W)

        # –ö–Ω–æ–ø–∫–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        button_frame = tk.Frame(control_frame)
        button_frame.pack(side=tk.RIGHT)

        self.record_btn = tk.Button(
            button_frame,
            text="üé§ –ù–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å",
            command=self.toggle_recording,
            font=("Arial", 12, "bold"),
            bg="#27ae60",
            fg="white",
            padx=20,
            pady=10,
            state=tk.DISABLED
        )
        self.record_btn.pack(side=tk.LEFT, padx=5)

        self.clear_btn = tk.Button(
            button_frame,
            text="üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å",
            command=self.clear_text,
            font=("Arial", 11),
            bg="#e74c3c",
            fg="white",
            padx=15,
            pady=8,
            state=tk.DISABLED
        )
        self.clear_btn.pack(side=tk.LEFT, padx=5)

        self.save_btn = tk.Button(
            button_frame,
            text="üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å",
            command=self.save_text,
            font=("Arial", 11),
            bg="#3498db",
            fg="white",
            padx=15,
            pady=8,
            state=tk.DISABLED
        )
        self.save_btn.pack(side=tk.LEFT, padx=5)

    def _load_models(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –£–õ–£–ß–®–ï–ù–ù–´–• –º–æ–¥–µ–ª–µ–π"""
        try:
            self.status_queue.put("üì• –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏...")

            # Vosk –º–æ–¥–µ–ª—å
            model_path = os.path.join("models", "vosk-model-small-ru-0.22")
            if not os.path.isdir(model_path):
                raise FileNotFoundError(f"–ú–æ–¥–µ–ª—å Vosk –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {model_path}")

            self.vosk_model = Model(model_path)

            # ‚ö° –£–õ–£–ß–®–ï–ù–ò–ï: –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
            self.status_queue.put("üì• –ó–∞–≥—Ä—É–∂–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω—É—é LLM (RUT5-Normalizer)...")

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞
            model_name = "cointegrated/rut5-small-normalizer"
            self.llm_tokenizer = AutoTokenizer.from_pretrained(model_name)
            self.llm_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)
            self.llm_model.eval()

            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            self.llm_model.to(self.device)

            self.models_loaded = True
            self.status_queue.put("‚úÖ –ú–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã! –ì–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ.")

        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π: {e}")
            self.status_queue.put(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {str(e)}")

    def _process_queues(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—á–µ—Ä–µ–¥–µ–π"""
        # –°—Ç–∞—Ç—É—Å—ã
        try:
            while True:
                status = self.status_queue.get_nowait()
                self.status_var.set(status)

                if status.startswith("‚úÖ –ú–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã"):
                    self.progress.stop()
                    self.progress_frame.pack_forget()
                    self.record_btn.config(state=tk.NORMAL)
                    self.clear_btn.config(state=tk.NORMAL)
                    self.save_btn.config(state=tk.NORMAL)

        except queue.Empty:
            pass

        # –¢–µ–∫—Å—Ç
        try:
            while True:
                text_data = self.text_queue.get_nowait()
                self._process_text_data(text_data)
        except queue.Empty:
            pass

        self.root.after(100, self._process_queues)

    def _process_text_data(self, text_data):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        text_type, text, metadata = text_data

        if text_type == "raw":
            # –°—ã—Ä–æ–π —Ç–µ–∫—Å—Ç - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ä–∞–∑—É
            self._append_text(f"üîπ {text}\n", "raw")
            self.last_raw_text = text

        elif text_type == "enhanced":
            # –£–ª—É—á—à–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç - –∑–∞–º–µ–Ω—è–µ–º —Å—ã—Ä–æ–π
            changes = metadata.get('changes', [])
            if changes:
                self.status_queue.put(f"‚úÖ –£–ª—É—á—à–µ–Ω–æ: {', '.join(changes)}")
            self._replace_last_text(f"‚ú® {text}\n\n")

        elif text_type == "partial":
            # –ß–∞—Å—Ç–∏—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            self.status_var.set(f"üé§ –†–∞—Å–ø–æ–∑–Ω–∞—é: {text}...")

        elif text_type == "llm_processing":
            # –°—Ç–∞—Ç—É—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ LLM
            self.status_var.set("‚úçÔ∏è –£–ª—É—á—à–∞–µ–º —Ç–µ–∫—Å—Ç...")

    def _append_text(self, text, text_type="normal"):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å —Ä–∞–∑–Ω—ã–º–∏ —Å—Ç–∏–ª—è–º–∏"""
        self.text_widget.config(state=tk.NORMAL)

        if text_type == "raw":
            # –°—ã—Ä–æ–π —Ç–µ–∫—Å—Ç - —Å–µ—Ä—ã–π —Ü–≤–µ—Ç
            self.text_widget.insert(tk.END, text)
            self.text_widget.tag_add("raw", "end-2l", "end-1l")
            self.text_widget.tag_config("raw", foreground="gray")
        else:
            self.text_widget.insert(tk.END, text)

        self.text_widget.see(tk.END)
        self.text_widget.config(state=tk.DISABLED)

    def _replace_last_text(self, enhanced_text):
        """–ó–∞–º–µ–Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å—ã—Ä–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ —É–ª—É—á—à–µ–Ω–Ω—ã–º"""
        self.text_widget.config(state=tk.NORMAL)

        # –ù–∞—Ö–æ–¥–∏–º –∏ —É–¥–∞–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—ã—Ä—É—é —Å—Ç—Ä–æ–∫—É
        content = self.text_widget.get("1.0", tk.END)
        lines = content.split('\n')

        for i in range(len(lines) - 1, -1, -1):
            if lines[i].startswith("üîπ"):
                # –£–¥–∞–ª—è–µ–º —ç—Ç—É —Å—Ç—Ä–æ–∫—É
                line_start = f"{i + 1}.0"
                line_end = f"{i + 2}.0"
                self.text_widget.delete(line_start, line_end)
                break

        # –î–æ–±–∞–≤–ª—è–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        self.text_widget.insert(tk.END, enhanced_text)
        self.text_widget.see(tk.END)
        self.text_widget.config(state=tk.DISABLED)

    def _needs_llm_correction(self, text):
        """‚ö° –£–õ–£–ß–®–ï–ù–ò–ï: –£–º–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ LLM"""
        words = text.split()

        # –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Ñ—Ä–∞–∑—ã –Ω–µ –Ω—É–∂–¥–∞—é—Ç—Å—è –≤ LLM
        if len(words) < 3:
            return False

        # –ï—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å –ø—É–Ω–∫—Ç—É–∞—Ü–∏—è –∏ —Ñ—Ä–∞–∑–∞ –∫–æ—Ä–æ—Ç–∫–∞—è - –Ω–µ –Ω—É–∂–Ω–æ
        if any(punct in text for punct in '.!?') and len(words) < 6:
            return False

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏, –≥–¥–µ LLM —Ä–µ–∞–ª—å–Ω–æ –ø–æ–º–æ–∂–µ—Ç
        needs_correction = (
            # –î–ª–∏–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã –±–µ–∑ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏
                (len(words) >= 4 and not any(punct in text for punct in '.!?,:')) or
                # –ï—Å—Ç—å —á–∏—Å–ª–∞, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–Ω–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å
                any(word.isdigit() for word in words) or
                # –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –æ–º–æ—Ñ–æ–Ω—ã –∏–ª–∏ —Å–ª–∏—Ç–Ω–æ–µ –Ω–∞–ø–∏—Å–∞–Ω–∏–µ
                any(pattern in text.lower() for pattern in [
                    '–∫–∞–∫–¥–µ–ª–∞', '—á—Ç–æ—Ç—ã', '—á—Ç–æ–±—ã', '–∑–∞—á–µ–º—Ç—ã', '–ø–æ—Ç–æ–º—É—á—Ç–æ'
                ]) or
                # –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø—Ä–µ–¥–ª–æ–≥–∏ –≤ –Ω—É–∂–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö
                self._missing_prepositions(text)
        )

        return needs_correction

    def _missing_prepositions(self, text):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –ø—Ä–µ–¥–ª–æ–≥–æ–≤"""
        words = text.split()
        common_verbs = ['–ø–æ—à–µ–ª', '–ø—Ä–∏—à–µ–ª', '—É—à–µ–ª', '–≤–µ—Ä–Ω—É–ª—Å—è', '–∑–∞—à–µ–ª']
        following_nouns = ['–º–∞–≥–∞–∑–∏–Ω', '–¥–æ–º', '—Ä–∞–±–æ—Ç–∞', '—É–ª–∏—Ü–∞', '–ø–∞—Ä–∫']

        for i, word in enumerate(words[:-1]):
            if word in common_verbs and words[i + 1] in following_nouns:
                return True
        return False

    def _enhance_with_llm(self, text):
        """‚ö° –£–õ–£–ß–®–ï–ù–ò–ï: –†–µ–∞–ª—å–Ω–æ –ø–æ–ª–µ–∑–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞"""
        if not text.strip():
            return text, []

        try:
            # ‚ö° –£–õ–£–ß–®–ï–ù–ò–ï: –ü–æ–¥–∞–µ–º —Ç–µ–∫—Å—Ç –ë–ï–ó –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤ - –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä —Å–∞–º –ø–æ–Ω–∏–º–∞–µ—Ç –∑–∞–¥–∞—á—É
            prompt = text

            inputs = self.llm_tokenizer(
                [prompt],
                return_tensors="pt",
                max_length=150,
                truncation=True,
                padding=True
            ).to(self.device)

            with torch.no_grad():
                outputs = self.llm_model.generate(
                    **inputs,
                    max_length=200,
                    num_beams=3,
                    early_stopping=True,
                    temperature=0.1,  # –ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
                    no_repeat_ngram_size=2
                )

            result = self.llm_tokenizer.decode(outputs[0], skip_special_tokens=True).strip()

            # ‚ö° –£–õ–£–ß–®–ï–ù–ò–ï: –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
            changes = self._analyze_changes(text, result)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —É–ª—É—á—à–µ–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –ø–æ–ª–µ–∑–Ω–æ
            if self._is_improvement_worthwhile(text, result, changes):
                return result, changes
            else:
                return text, []

        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ LLM —É–ª—É—á—à–µ–Ω–∏—è: {e}")
            return text, []

    def _analyze_changes(self, original, enhanced):
        """–ê–Ω–∞–ª–∏–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π –º–µ–∂–¥—É –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–º –∏ —É–ª—É—á—à–µ–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–µ–π"""
        if original == enhanced:
            return []

        changes = []
        orig_words = original.split()
        enh_words = enhanced.split()

        # –ü—Ä–æ—Å—Ç—ã–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
        if len(orig_words) != len(enh_words):
            changes.append("—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏
        orig_punct = set(re.findall(r'[.,!?;:]', original))
        enh_punct = set(re.findall(r'[.,!?;:]', enhanced))
        new_punct = enh_punct - orig_punct
        if new_punct:
            changes.append("–ø—É–Ω–∫—Ç—É–∞—Ü–∏—è")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–µ–¥–ª–æ–≥–æ–≤
        prepositions = ['–≤', '–Ω–∞', '–∑–∞', '–ø–æ–¥', '–æ', '—É', '—Å', '–ø–æ']
        orig_prep = sum(1 for word in orig_words if word in prepositions)
        enh_prep = sum(1 for word in enh_words if word in prepositions)
        if enh_prep > orig_prep:
            changes.append("–ø—Ä–µ–¥–ª–æ–≥–∏")

        return changes

    def _is_improvement_worthwhile(self, original, enhanced, changes):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ —É–ª—É—á—à–µ–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –ø–æ–ª–µ–∑–Ω–æ"""
        if not changes:
            return False

        # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç —Å—Ç–∞–ª –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –∫–æ—Ä–æ—á–µ/–¥–ª–∏–Ω–Ω–µ–µ –±–µ–∑ —è–≤–Ω–æ–π –ø–æ–ª—å–∑—ã
        len_diff = abs(len(enhanced) - len(original)) / len(original)
        if len_diff > 0.5:  # –ë–æ–ª–µ–µ 50% –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥–ª–∏–Ω—ã
            return False

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ—Å–Ω–æ–≤–Ω—ã–µ —Å–ª–æ–≤–∞ —Å–æ—Ö—Ä–∞–Ω–∏–ª–∏—Å—å
        orig_words = set(original.lower().split())
        enh_words = set(enhanced.lower().split())
        common_words = orig_words.intersection(enh_words)

        if len(common_words) / max(len(orig_words), 1) < 0.6:
            return False  # –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∏–∑–º–µ–Ω–µ–Ω–∏–π

        return True

    def toggle_recording(self):
        if not self.is_recording:
            self.start_recording()
        else:
            self.stop_recording()

    def start_recording(self):
        if not self.models_loaded:
            messagebox.showerror("–û—à–∏–±–∫–∞", "–ú–æ–¥–µ–ª–∏ –µ—â–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")
            return

        with self.recording_lock:
            if self.is_recording:
                return
            self.is_recording = True
            self.stop_event.clear()

        self.record_btn.config(text="‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å", bg="#c0392b")
        self.status_var.set("üé§ –ó–∞–ø–∏—Å—å... –ì–æ–≤–æ—Ä–∏—Ç–µ!")

        self.worker_thread = threading.Thread(target=self._recording_worker, daemon=True)
        self.worker_thread.start()

    def _recording_worker(self):
        """–£–ª—É—á—à–µ–Ω–Ω—ã–π —Ä–∞–±–æ—á–∏–π –ø—Ä–æ—Ü–µ—Å—Å –∑–∞–ø–∏—Å–∏"""
        recognizer = KaldiRecognizer(self.vosk_model, self.sample_rate)

        def audio_callback(indata, frames, time, status):
            if self.stop_event.is_set():
                raise sd.CallbackStop()

            if status:
                logging.warning(f"–ê—É–¥–∏–æ —Å—Ç–∞—Ç—É—Å: {status}")

            try:
                pcm_data = (indata * 32767).astype(np.int16).tobytes()

                if recognizer.AcceptWaveform(pcm_data):
                    result = json.loads(recognizer.Result())
                    text = result.get("text", "").strip()
                    if text:
                        # –í—Å–µ–≥–¥–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—ã—Ä–æ–π —Ç–µ–∫—Å—Ç
                        self.text_queue.put(("raw", text, {}))

                        # ‚ö° –£–õ–£–ß–®–ï–ù–ò–ï: –£–º–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ LLM
                        if self.use_llm.get() and self._needs_llm_correction(text):
                            self.text_queue.put(("llm_processing", "", {}))
                            threading.Thread(
                                target=self._process_with_llm,
                                args=(text,),
                                daemon=True
                            ).start()
                        else:
                            # –ï—Å–ª–∏ LLM –Ω–µ –Ω—É–∂–Ω–∞, –ø—Ä–æ—Å—Ç–æ –∫–æ–ø–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –∫–∞–∫ —É–ª—É—á—à–µ–Ω–Ω—ã–π
                            self.text_queue.put(("enhanced", text, {'changes': []}))

                else:
                    # –ß–∞—Å—Ç–∏—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                    partial = json.loads(recognizer.PartialResult())
                    partial_text = partial.get("partial", "")
                    if partial_text:
                        self.text_queue.put(("partial", partial_text, {}))

            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –≤ callback: {e}")
                self.stop_event.set()

        try:
            with sd.InputStream(
                    samplerate=self.sample_rate,
                    channels=1,
                    dtype='float32',
                    blocksize=self.chunk_size,
                    callback=audio_callback,
                    latency='low'
            ):
                while not self.stop_event.is_set():
                    sd.sleep(100)

        except sd.CallbackStop:
            logging.info("–ó–∞–ø–∏—Å—å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏: {e}")
            self.status_queue.put(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏: {str(e)}")
        finally:
            self._finalize_recording(recognizer)

    def _process_with_llm(self, text):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ LLM"""
        try:
            enhanced, changes = self._enhance_with_llm(text)
            self.text_queue.put(("enhanced", enhanced, {'changes': changes}))
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ LLM –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
            self.text_queue.put(("enhanced", text, {'changes': []}))

    def _finalize_recording(self, recognizer):
        """–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∏"""
        try:
            final_result = json.loads(recognizer.FinalResult())
            final_text = final_result.get("text", "").strip()
            if final_text:
                self.text_queue.put(("enhanced", final_text, {'changes': []}))
        except Exception as e:
            logging.warning(f"–û—à–∏–±–∫–∞ —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
        finally:
            with self.recording_lock:
                self.is_recording = False
            self.root.after(0, self._recording_stopped_ui)

    def _recording_stopped_ui(self):
        """–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ UI"""
        self.record_btn.config(
            text="üé§ –ù–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å",
            bg="#27ae60",
            state=tk.NORMAL
        )
        self.status_var.set("‚úÖ –ó–∞–ø–∏—Å—å –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

    def stop_recording(self):
        if not self.is_recording:
            return

        self.stop_event.set()
        self.record_btn.config(state=tk.DISABLED)
        self.status_var.set("üîÑ –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞...")

    def clear_text(self):
        self.text_widget.config(state=tk.NORMAL)
        self.text_widget.delete("1.0", tk.END)
        self.text_widget.config(state=tk.DISABLED)
        self.last_raw_text = ""
        self.status_var.set("üìù –¢–µ–∫—Å—Ç –æ—á–∏—â–µ–Ω")

    def save_text(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ —Ñ–∞–π–ª"""
        try:
            text_content = self.text_widget.get("1.0", tk.END).strip()
            if not text_content:
                messagebox.showwarning("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ", "–ù–µ—Ç —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
                return

            from tkinter import filedialog
            file_path = filedialog.asksaveasfilename(
                defaultextension=".txt",
                filetypes=[("–¢–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã", "*.txt"), ("–í—Å–µ —Ñ–∞–π–ª—ã", "*.*")]
            )

            if file_path:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(text_content)
                self.status_var.set(f"‚úÖ –¢–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {os.path.basename(file_path)}")

        except Exception as e:
            messagebox.showerror("–û—à–∏–±–∫–∞", f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–∞–π–ª: {str(e)}")


def main():
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(levelname)s - %(message)s",
        handlers=[
            logging.FileHandler("transcriber.log", encoding='utf-8'),
            logging.StreamHandler()
        ]
    )

    try:
        root = tk.Tk()
        app = ProfessionalVoiceTranscriber(root)
        root.mainloop()
    except Exception as e:
        logging.critical(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        messagebox.showerror("–û—à–∏–±–∫–∞", f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ:\n{str(e)}")


if __name__ == "__main__":
    main()
